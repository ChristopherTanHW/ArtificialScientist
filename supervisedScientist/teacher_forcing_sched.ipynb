{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import typing\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading in rollout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('rollout_dataset_pickled','rb')\n",
    "dataset = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relstat_emb': [189, 184, 212, 213, 178, 199, 185, 180, 178],\n",
       " 'task_emb': tensor([[[253, 210, 212, 213,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]]),\n",
       " 'rollout': tensor([[[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[198, 214,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[199, 214,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[180, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[181, 191,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[198, 214,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[199, 214,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[180, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[181, 191,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[199, 214,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[180, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[181, 191,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[180, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[181, 191,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[180, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[181, 191,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]],\n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       "         [[[[[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[201,  35,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[179, 190,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[182, 189,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[183,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[199,  53,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[170,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]],\n",
       " \n",
       " \n",
       "            [[[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]],\n",
       " \n",
       "             [[  3,   0,   0,  ...,   0,   0,   0]]]]]]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of dataset entry\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and other helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_token = 1\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n",
    "          decoder_optimizer, criterion, vocab_size, teacher_forcing_ratio, max_length=15):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    #print('target_length: ', target_length)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    decoder_input = torch.tensor([[0]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder(input_tensor).view(1,1,-1)\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            #print('recur decoder_input: ', decoder_input)\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            #print('decoder output: ', decoder_output)\n",
    "            #print('target tensor di: ', target_tensor[di].view(1))\n",
    "            loss += criterion(decoder_output, target_tensor[di].view(1).long())\n",
    "            decoder_input = target_tensor[di].view(1).long() # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di].view(1).long())\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def pad_rollouts(rollout, max_len):\n",
    "    rollout_len = rollout.size()[0]\n",
    "    if rollout_len > max_len - 1:\n",
    "        print('rollout too long')\n",
    "        return None\n",
    "    remaining = max_len - rollout_len\n",
    "    padding = torch.zeros((remaining, 1, 1, 6, 6, 1, 8))\n",
    "    padded_rollout = torch.cat((rollout, padding), 0)\n",
    "    return padded_rollout\n",
    "\n",
    "#pads all relevant statement embeddings to some max len and returns their flattened tensor\n",
    "def preprocess_relstat_emb(relstat_emb, max_len = 15):\n",
    "    l = torch.zeros([1])\n",
    "    torch_relstat = torch.tensor(relstat_emb)\n",
    "    l = torch.cat((l,torch_relstat))\n",
    "    if l.size(0) > max_len:\n",
    "        print('relstat too long')\n",
    "        return None\n",
    "    while l.size()[0] < max_len:\n",
    "        l = torch.cat((l, torch.ones([1])))\n",
    "        l = l.flatten()\n",
    "    return l\n",
    "\n",
    "def flatten_all(dataset, max_len_rollout, max_len_relstat):\n",
    "    flat_dataset = []\n",
    "    for i in range(len(dataset)):\n",
    "        entry = []\n",
    "        flat_task = torch.flatten(dataset[i]['task_emb'])\n",
    "        padded_rollout = pad_rollouts(dataset[i]['rollout'], max_len_rollout)\n",
    "        flat_rollout = padded_rollout.flatten()\n",
    "        processed_relstat = preprocess_relstat_emb(dataset[i]['relstat_emb'], max_len_relstat)\n",
    "        entry.append(torch.cat((flat_task, flat_rollout)))\n",
    "        entry.append(processed_relstat)\n",
    "        flat_dataset.append(entry)\n",
    "    return flat_dataset\n",
    "\n",
    "def trainIters(dataset, encoder, decoder, n_iters, output_size, teacher_forcing_low, print_every=100, plot_every=10, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = dataset\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        teacher_forcing_ratio = 1 - (iter / n_iters) * teacher_forcing_low\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, output_size, teacher_forcing_ratio)\n",
    "        #print('loss: ', loss)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)\n",
    "    return plot_losses\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_dataset = flatten_all(dataset, 21, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten rollouts, train-test split, and random shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dataset = flatten_all(dataset, 30, 15)\n",
    "flat_train = flat_dataset[:99000]\n",
    "flat_test = flat_dataset[1000:]\n",
    "random.shuffle(flat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  8680\n"
     ]
    }
   ],
   "source": [
    "#inspecting input dimensionality\n",
    "input_size = flat_dataset[0][0].size()[0]\n",
    "print('input size: ', input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 262\n",
    "latent_size = 200\n",
    "encoder = LinearEncoder(input_size, latent_size).to(device)\n",
    "decoder = DecoderRNN(latent_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to around a million for interesting results\n",
    "n_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 1s (- 0m 14s) (100 10%) 3.3560\n",
      "0m 3s (- 0m 12s) (200 20%) 1.6682\n",
      "0m 4s (- 0m 10s) (300 30%) 1.2949\n",
      "0m 5s (- 0m 8s) (400 40%) 1.1347\n",
      "0m 7s (- 0m 7s) (500 50%) 0.9729\n",
      "0m 9s (- 0m 6s) (600 60%) 0.9083\n",
      "0m 11s (- 0m 4s) (700 70%) 0.9981\n",
      "0m 12s (- 0m 3s) (800 80%) 0.9510\n",
      "0m 14s (- 0m 1s) (900 90%) 1.0415\n",
      "0m 15s (- 0m 0s) (1000 100%) 1.0557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = trainIters(flat_train, encoder, decoder, n_iters, output_size, 0.5, print_every=100, plot_every=100, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary of RTFM\n",
    "vocab = ['pad', 'eos', '', 'wall', 'door', 'orcishdagger', 'dagger', 'silverdagger', 'athame', \n",
    "         'elvendagger', 'wormtooth', 'knife', 'stiletto', 'scalpel', 'crysknife', 'axe', 'battleaxe', \n",
    "         'pickaxe', 'dwarvishmattock', 'orcishshortsword', 'shortsword', 'dwarvishshortsword', \n",
    "         'elvenshortsword', 'broadsword', 'runesword', 'elvenbroadsword', 'longsword', 'katana', \n",
    "         'twohandedsword', 'tsurugi', 'scimitar', 'silversaber', 'club', 'aklys', 'mace', 'morningstar', \n",
    "         'flail', 'grapplinghook', 'warhammer', 'quarterstaff', 'partisan', 'fauchard', 'glaive', 'becdecorbin', \n",
    "         'spetum', 'lucernhammer', 'guisarme', 'ranseur', 'voulge', 'billguisarme', 'bardiche', 'halberd', \n",
    "         'orcishspear', 'spear', 'silverspear', 'elvenspear', 'dwarvishspear', 'javelin', 'trident', 'lance', \n",
    "         'orcishbow', 'orcisharrow', 'bow', 'arrow', 'elvenbow', 'elvenarrow', 'yumi', 'ya', 'silverarrow', \n",
    "         'sling', 'flintstone', 'crossbow', 'crossbowbolt', 'dart', 'shuriken', 'boomerang', 'bullwhip', \n",
    "         'rubberhose', 'unicornhorn', 'unarmed', 'basedagger', 'baseknive', 'baseaxe', 'basepickaxe', \n",
    "         'baseshortsword', 'basebroadsword', 'baselongsword', 'basetwohandedsword', 'basescimitar', \n",
    "         'basesaber', 'baseclub', 'basemace', 'basemorningstar', 'baseflail', 'basehammer', 'basequarterstave', \n",
    "         'basepolearm', 'basespear', 'basetrident', 'baselance', 'basebow', 'basesling', 'basecrossbow', 'basedart', \n",
    "         'baseshuriken', 'baseboomerang', 'basewhip', 'baseunicornhorn', 'hawaiianshirt', 'tshirt', 'leatherjacket', \n",
    "         'leatherarmor', 'orcishringmail', 'studdedleatherarmor', 'ringmail', 'scalemail', 'orcishchainmail', \n",
    "         'chainmail', 'elvenmithrilcoat', 'splintmail', 'bandedmail', 'dwarvishmithrilcoat', 'bronzeplatemail', \n",
    "         'platemail', 'crystalplatemail', 'dragonscales', 'mummywrapping', 'orcishcloak', 'dwarvishcloak', \n",
    "         'leathercloak', 'oilskincloak', 'fedora', 'dentedpot', 'elvenleatherhelm', 'helmet', 'orcishhelm', \n",
    "         'dwarvishironhelm', 'leathergloves', 'smallshield', 'orcishshield', 'urukhaishield', 'elvenshield', \n",
    "         'dwarvishroundshield', 'largeshield', 'lowboots', 'highboots', 'ironshoes', 'baseshirt', 'basesuit', \n",
    "         'basedragonsuit', 'basecloak', 'basehelm', 'baseglove', 'baseshield', 'baseboot', 'amulet', 'ring', \n",
    "         'weapon', 'armour', 'accessory', 'agent', 'player', 'queuedagent', 'monster', 'stationarymonster', \n",
    "         'dragon', 'hostilemonster', 'randommonster', 'structure', 'unobservable', 'empty', 'baseitem', \n",
    "         'basemonster', 'move', 'around', 'welcome', 'to', 'rtfm', '.', 'cold', 'fire', 'poison', 'lightning', \n",
    "         'you', 'are', 'beat', ',', '{', '}', 'wolf', 'jaguar', 'panther', 'goblin', 'bat', 'imp', 'shaman', \n",
    "         'ghost', 'zombie', 'grandmasters', 'blessed', 'shimmering', 'gleaming', 'fanatical', 'mysterious', \n",
    "         'soldiers', 'arcane', 'star', 'alliance', 'order', 'of', 'the', 'forest', 'rebel', 'enclave', 'sword', \n",
    "         'polearm', 'cutlass', 'modifiers', 'weapons', 'element', 'monsters', 'items', 'effective', 'against', \n",
    "         'defeated', 'by', 'should', 'use', 'get', 'slay', 'useful', 'for', 'good', 'not', 'weak', 'slain', \n",
    "         'group', 'belong', 'contains', 'on', 'team', 'consists', 'same', '-', 'they', 'has', 'following', \n",
    "         'members', ':', 'is', 'made', 'up', 'make', 'defeat', 'must', 'be', 'needs', 'beaten', 'evil', 'fight', \n",
    "         'in', 'from']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pred(pred):\n",
    "    newls = []\n",
    "    for l in pred:\n",
    "        if l == 'pad' or l == '<EOS>':\n",
    "            continue\n",
    "        newls.append(l)\n",
    "    return newls\n",
    "\n",
    "def clean_eval(targets, preds):\n",
    "    cleant = []\n",
    "    for t in targets:\n",
    "        clean_tar = clean_target(t)\n",
    "        cleant.append(clean_tar)\n",
    "    \n",
    "    cleanp = []\n",
    "    for p in preds:\n",
    "        clean_pre = clean_pred(p)\n",
    "        cleanp.append(clean_pre)\n",
    "    return cleant, cleanp\n",
    "\n",
    "def clean_target(target):\n",
    "    ls = target.split()\n",
    "    newls = []\n",
    "    for l in ls:\n",
    "        if l == 'pad' or l == 'eos':\n",
    "            continue\n",
    "        newls.append(l)\n",
    "    return newls\n",
    "\n",
    "def idx_to_sent(idxs, vocab):\n",
    "    sent = ''\n",
    "    idxs = idxs.int()\n",
    "    for i in idxs:\n",
    "        sent += vocab[i] +' '\n",
    "    return sent\n",
    "\n",
    "def evaluate(encoder, decoder, input_tensor, vocab, max_length=15):\n",
    "    with torch.no_grad():\n",
    "        latent = encoder(input_tensor)\n",
    "\n",
    "        decoder_input = torch.tensor([[0]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = latent.view(1,1,-1)\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == 1:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(vocab[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, pairs, vocab, n=10):\n",
    "    target = []\n",
    "    predicted = []\n",
    "    for i in range(n):\n",
    "        pair = pairs[i]\n",
    "        target_statements = idx_to_sent(pair[1], vocab)\n",
    "        target.append(target_statements)\n",
    "        output_words = evaluate(encoder, decoder, pair[0], vocab)\n",
    "        predicted.append(output_words)\n",
    "        #output_sentence = ' '.join(output_words)\n",
    "        #print('<', output_sentence)\n",
    "        #print('')\n",
    "    return target, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, preds = evaluateRandomly(encoder, decoder, flat_train, vocab, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  pad blessed beat poison . wolf are rebel enclave . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad shimmering beat fire . panther are star alliance . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad jaguar are order of the forest . blessed beat lightning . eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad blessed beat lightning . jaguar are rebel enclave . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad gleaming beat fire . panther are order of the forest . eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad grandmasters beat lightning . panther are order of the forest . eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad shimmering beat cold . panther are rebel enclave . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad gleaming beat poison . jaguar are rebel enclave . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad shimmering beat poison . jaguar are rebel enclave . eos eos eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n",
      "target:  pad jaguar are order of the forest . blessed beat fire . eos eos eos \n",
      "preds:  ['pad', 'gleaming', 'beat', 'poison', '.', 'panther', 'are', 'order', 'of', 'the', 'forest', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(targets)):\n",
    "    print('target: ', targets[i])\n",
    "    print('preds: ', preds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-gram individual BLEU\n",
    "from nltk.translate.bleu_score import sentence_bleu \n",
    "reference = [['this', 'is', 'a', 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "print('Individual 1-gram: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0)))\n",
    "print('Individual 2-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 1, 0, 0)))\n",
    "print('Individual 3-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 1, 0)))\n",
    "print('Individual 4-gram: %f' % sentence_bleu(reference, candidate, weights=(0, 0, 0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manualCVenv",
   "language": "python",
   "name": "manualcvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
